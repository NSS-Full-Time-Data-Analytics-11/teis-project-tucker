{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743de782",
   "metadata": {},
   "outputs": [],
   "source": [
    "teis = pd.read_csv('data/teis.csv', dtype = {\"Child ID\" : object, \"Cognitive T-Score\" : object})\n",
    "teis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "teis.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls = teis[['Child ID',\n",
    " 'Gender',\n",
    " 'Date of Birth',\n",
    " 'Location - Sub Level 1',\n",
    " 'Program Label','Adaptive Developmental Quotient',\n",
    " 'Adaptive Percentile Rank','Social-Emotional Developmental Quotient',\n",
    " 'Social-Emotional Percentile Rank','Communication Developmental Quotient',\n",
    " 'Communication Percentile Rank','Motor Developmental Quotient',\n",
    " 'Motor Percentile Rank','Cognitive Developmental Quotient',\n",
    " 'Cognitive Percentile Rank',\n",
    " 'BDI-3 Total Developmental Quotient',\n",
    " 'BDI-3 Total Percentile Rank',\n",
    " 'Adaptive-Self Care Examiner',\n",
    " 'Adaptive-Self Care Date of Testing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaea385",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aba26c",
   "metadata": {},
   "source": [
    "6. Is there any difference in scoring noted based on evaluation type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligibility_eval = pulls[pulls['Program Label'] == 'BDI-3 Eligibility Evaluation']\n",
    "annual_eval = pulls[pulls['Program Label'] == 'BDI-3 Annual Evaluation']\n",
    "milestone_exit_eval = pulls[pulls['Program Label'] == 'BDI-3 Milestone or Exit Evaluation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad65db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligibility_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fedf621",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_score_columns = [col for col in pulls.columns if pd.api.types.is_numeric_dtype(pulls[col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccdcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_eligibility_numeric = eligibility_eval[numeric_score_columns].mean()\n",
    "mean_annual_numeric = annual_eval[numeric_score_columns].mean()\n",
    "mean_milestone_exit_numeric = milestone_exit_eval[numeric_score_columns].mean()\n",
    "mean_scores_comparison_numeric = pd.DataFrame({\n",
    "    'Eligibility Evaluation': mean_eligibility_numeric,\n",
    "    'Annual Evaluation': mean_annual_numeric,\n",
    "    'Milestone/Exit Evaluation': mean_milestone_exit_numeric\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores_comparison_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f2878",
   "metadata": {},
   "source": [
    "6. Is there any difference in scoring noted based on evaluation type? improvement between eligibility and exut, annual is scattered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e20c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce1eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8a601e",
   "metadata": {},
   "source": [
    "7. Is there any notable pattern of scoring by region? Note: TEIS contracts with three agencies for evaluations (one per grand region) as follows:\n",
    "* East TN, First TN and Southeast\n",
    "* Greater Nashville, Upper Cumberland, and South Central\n",
    "* Northwest, Southwest, and Memphis Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Region(x):\n",
    "    if x in ('East Tennessee', 'First Tennessee', 'Southeast Tennessee'):\n",
    "        return 'East TN'\n",
    "    elif x in ('Greater Nashville', 'Upper Cumberland', 'South Central'):\n",
    "        return 'Middle TN'\n",
    "    elif x in ('Northwest', 'Southwest', 'Memphis Delta'):\n",
    "        return 'West TN'\n",
    "pulls['Region'] = pulls['Location - Sub Level 1'].apply(Region)\n",
    "pulls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot( x=pulls[\"Region\"], y=pulls[\"BDI-3 Total Percentile Rank\"] );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls.columns = [c.replace('_', ' ') for c in pulls.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls.boxplot(column =['Adaptive Percentile Rank', 'Social Emotional Percentile Rank', 'Communication Percentile Rank', 'Motor Percentile Rank', 'Cognitive Percentile Rank', 'BDI 3 Total Percentile Rank'], by='Region', figsize=(12, 9), layout = (2, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869aa3b",
   "metadata": {},
   "source": [
    "8. Is there any notable pattern of scoring by evaluator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls = pulls.rename(columns={'Adaptive Self Care Examiner': 'Examiner'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e584a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pulls.Examiner.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752396f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(pulls['BDI 3 Total Percentile Rank']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(pulls['Adaptive Percentile Rank']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619da16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056791b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad1c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f770a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
